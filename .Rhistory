n.thin = nt,
n.iter = ni,
n.burnin = nb)
library(R2jags)
n <- 50
mu <- 1.12
sigma <- 0.38
# Generate values (stochastic part of the model)
set.seed(214) # so we all get the same random numbers
yi <- rnorm(n, mean=mu, sd=sigma)
# Mean and SD of sample
mean(yi)
sd(yi)
# Get frequentist confidence interval for the mean
t.test(yi)$conf.int[1:2]
sink("model.txt")
cat("
model {
# Likelihood
# Priors
# Derived quantities
} # end model
",fill = TRUE)
sink()
data <- list(y = yi,
n = n )
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
library(R2jags)
n <- 50
mu <- 1.12
sigma <- 0.38
# Generate values (stochastic part of the model)
set.seed(214) # so we all get the same random numbers
yi <- rnorm(n, mean=mu, sd=sigma)
# Mean and SD of sample
mean(yi)
sd(yi)
# Get frequentist confidence interval for the mean
t.test(yi)$conf.int[1:2]
sink("model.txt")
cat("
model {
} # end model
",fill = TRUE)
sink()
data <- list(y = yi,
n = n )
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
library(R2jags)
n <- 50
mu <- 1.12
sigma <- 0.38
# Generate values (stochastic part of the model)
set.seed(214) # so we all get the same random numbers
yi <- rnorm(n, mean=mu, sd=sigma)
# Mean and SD of sample
mean(yi)
sd(yi)
# Get frequentist confidence interval for the mean
t.test(yi)$conf.int[1:2]
sink("model.txt")
cat("
model {
} # end model
sink("model.txt")
cat("
model {
} # end model
",fill = TRUE)
sink()
sink()
data <- list(y = yi,
n = n )
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
out
rm(list = ls())
library(R2jags)
n <- 50
mu <- 1.12
sigma <- 0.38
# Generate values (stochastic part of the model)
set.seed(214) # so we all get the same random numbers
yi <- rnorm(n, mean=mu, sd=sigma)
# Mean and SD of sample
mean(yi)
sd(yi)
# Get frequentist confidence interval for the mean
t.test(yi)$conf.int[1:2]
sink("model.txt")
cat("
model {
# Likelihood
# Priors
# Derived quantities
} # end model
",fill = TRUE)
sink()
data <- list(y = yi,
n = n )
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
library(R2jags)
n <- 50
mu <- 1.12
sigma <- 0.38
# Generate values (stochastic part of the model)
set.seed(214) # so we all get the same random numbers
yi <- rnorm(n, mean=mu, sd=sigma)
# Mean and SD of sample
mean(yi)
sd(yi)
# Get frequentist confidence interval for the mean
t.test(yi)$conf.int[1:2]
sink("model.txt")
cat("
",fill = TRUE)
sink()
data <- list(y = yi,
n = n )
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
library(R2jags)
n <- 50
mu <- 1.12
sigma <- 0.38
# Generate values (stochastic part of the model)
set.seed(214) # so we all get the same random numbers
yi <- rnorm(n, mean=mu, sd=sigma)
# Mean and SD of sample
mean(yi)
sd(yi)
# Get frequentist confidence interval for the mean
t.test(yi)$conf.int[1:2]
sink("model.txt")
cat("
model {
# Likelihood
# Priors
# Derived quantities
} # end model
",fill = TRUE)
sink()
data <- list(y = yi,
n = n )
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
n <- 50
mu <- 1.12
sigma <- 0.38
# Generate values (stochastic part of the model)
set.seed(214) # so we all get the same random numbers
yi <- rnorm(n, mean=mu, sd=sigma)
# Mean and SD of sample
mean(yi)
sd(yi)
# Get frequentist confidence interval for the mean
t.test(yi)$conf.int[1:2]
sink("model.txt")
cat("
model {
# Likelihood
# Priors
# Derived quantities
} # end model
",fill = TRUE)
sink()
data <- list(y = yi,
n = n )
inits <- function (){
list (mu=rnorm(1), sigma=runif(1) )
}
ni <- 1000
nt <- 2
nb <- 500
nc <- 3
parameters <- c("mu","sigma")
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
out <- jags(data,
inits,
parameters,
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
View(data)
data
inits
parameters
model.txt
?sink
sink("model.txt")
cat("
model {
# Likelihood
# Priors
# Derived quantities
} # end model
",fill = TRUE)
"model.txt"
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
sink("model.txt")
cat("
model {
# Likelihood
# Priors
# Derived quantities
} # end model
",fill = TRUE)
sink()
out <- jags(data,
inits,
parameters,
"model.txt",
n.chains = nc,
n.thin = nt,
n.iter = ni,
n.burnin = nb)
n.chains
nc
?jags
library(readr)
tbl_sarsCov2 <- read_csv("Downloads/Archiv(2)/tbl_sarsCov2.csv")
View(tbl_sarsCov2)
library(tidyverse)
tbl_sarsCov2 %>%
unique(sarsCov2Id)
tbl_sarsCov2 %>%
select(sarsCov2Id) %>%
unique()
library(readr)
tbl_sarsCov2 <- read_csv("Downloads/Archiv(2)/tbl_sarsCov2.csv")
View(tbl_sarsCov2)
library(readr)
tbl_sarsCov2 <- read_csv("Downloads/Archiv(2)/tbl_sarsCov2.csv",
col_types = cols(dt = col_date(format = "%d.%m.%Y")))
View(tbl_sarsCov2)
tbl_sarsCov2 <- read.csv("~/Downloads/Archiv(2)/tbl_sarsCov2.csv", header=FALSE)
View(tbl_sarsCov2)
library(readr)
tbl_sarsCov2 <- read_csv("Downloads/Archiv(2)/tbl_sarsCov2.csv",
col_types = cols(srcId = col_character(),
dt = col_date(format = "%d.%m.%y"),
date = col_date(format = "%d.%m.%y")))
View(tbl_sarsCov2)
tbl_sarsCov2 %>%
group_by(patId) %>%
summarise(positive = amountPositive > 0)
tbl_sarsCov2 %>%
group_by(patId) %>%
summarise(positive = amountPositive > 0) %>%
View()
library(readr)
tbl_respvir <- read_delim("Downloads/Archiv(2)/tbl_respvir.csv",
";", escape_double = FALSE, col_types = cols(dt = col_datetime(format = "%y-%m-%d %H:%M:%S")),
trim_ws = TRUE)
View(tbl_respvir)
library(readr)
tbl_respvir <- read_delim("Downloads/Archiv(2)/tbl_respvir.csv",
";", escape_double = FALSE, col_types = cols(dt = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
date = col_date(format = "%Y-%m-%d")),
trim_ws = TRUE)
View(tbl_respvir)
intersect(tbl_sarsCov2$patId, tbl_respvir$patId)
tbl_respvir %>%
filter(patId == intersect(tbl_sarsCov2$patId, tbl_respvir$patId)) %>%
View()
library(updateR)
updateR(admin_password = 'Admin user password')
library(updateR)
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
install.packages("devtools")
updateR(admin_password = 'Bumbel2304!')
library(updateR)
install_github('andreacirilloac/updateR')
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'Bumbel2304!')
library(updateR)
install_github('andreacirilloac/updateR')
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'Bumbel2304!')
updateR(admin_password = "Bumbel2304!")
updateR(admin_password = Bumbel2304!)
updateR()
rm(list = ls())
library(usethis)
usethis::edit_r_environ()
usethis::edit_r_environ()
parallel::stopCluster(cl = my.cluster)
library(tidyverse)
library(parallel)
library(foreach)
parallel::detectCores()
n.cores <- parallel::detectCores() - 4
#create the cluster
my.cluster <- parallel::makeCluster(
n.cores,
type = "PSOCK"
)
#check cluster definition (optional)
print(my.cluster)
#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)
#check if it is registered (optional)
foreach::getDoParRegistered()
#how many workers are available? (optional)
foreach::getDoParWorkers()
parallel::stopCluster(cl = my.cluster)
rm(list = ls())
library(tidyverse)
library(parallel)
library(foreach)
parallel::detectCores()
n.cores <- parallel::detectCores() - 4
#create the cluster
my.cluster <- parallel::makeCluster(
n.cores,
type = "PSOCK"
)
#check cluster definition (optional)
print(my.cluster)
#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)
#check if it is registered (optional)
foreach::getDoParRegistered()
#how many workers are available? (optional)
foreach::getDoParWorkers()
#### Loading databases ####
ihme.data <- NA
for(i in 1:6){
df <- read.table(paste0("ihme_",i,".csv"),sep=",", header=T)
ihme.data <- rbind(df,ihme.data)
}
rm(df)
income.db <- read.csv("ihme_income.csv")
#### Generating SD for iterations ####
ihme.data <- ihme.data %>% mutate(sd=(upper-lower)/(2*qnorm(0.975)))
#### Merging with income group data ####
ihme.data<- merge(ihme.data,income.db, by="location", all.y = T)
#### Loop to generate iterations ####
ihme.data.l <- ihme.data
n.it <- 1000
start.time <- Sys.time()
foreach(
i = 1:n.it,
.combine = 'c',
.packages = "tidyverse"
) %dopar% {
ihme.data.l$val <- apply(ihme.data,
1,
function(x) rnorm(1,
mean = x[8],
sd = x[11]))
ihme.data.l <- ihme.data.l %>%
mutate(val = ifelse(val < 0,
0,
val))
assign(paste0("ihme.data.it.",
i),
ihme.data.l)
}
parallel::stopCluster(cl = my.cluster)
end.time <- Sys.time()
end.time-start.time
rm(list = ls())
parallel::stopCluster(cl = my.cluster)
library(tidyverse)
library(parallel)
library(foreach)
parallel::detectCores()
n.cores <- parallel::detectCores() - 4
#create the cluster
my.cluster <- parallel::makeCluster(
n.cores,
type = "PSOCK"
)
#check cluster definition (optional)
print(my.cluster)
#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)
#check if it is registered (optional)
foreach::getDoParRegistered()
#how many workers are available? (optional)
foreach::getDoParWorkers()
parallel::stopCluster(cl = my.cluster)
setwd("~/Documents/starter-research-group")
rm(list = ls())
setwd("/Volumes/KINGSTON/USB Stick/Statistikplan EURAMOS/Daten_Lebensqualität_12102015")
setwd("~/Desktop/starter-research-group")
